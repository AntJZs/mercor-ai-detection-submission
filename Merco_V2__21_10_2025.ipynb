{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 117171,
          "databundleVersionId": 14089262,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Merco-V2->21-10-2025",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "EPpUbQdQvbca"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mercor_ai_detection_path = kagglehub.competition_download('mercor-ai-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "dnlu0ljKvbcc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "uBbvLyDrvbcc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Star with my solution"
      ],
      "metadata": {
        "id": "C8WhMba7vbcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  INSTALACI√ìN DE DEPENDENCIAS COMPATIBLES\n",
        "# ============================================================\n",
        "!pip install -U \\\n",
        "    sentence-transformers==2.6.1 \\\n",
        "    transformers==4.39.3 \\\n",
        "    huggingface_hub==0.22.2 \\\n",
        "    scikit-learn==1.5.2 \\\n",
        "    numpy==1.26.4 \\\n",
        "    xgboost==2.1.1 \\\n",
        "    joblib==1.4.2\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "N8KJtB1Uvbce"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codigo para Realizar clasificacion de Texto"
      ],
      "metadata": {
        "id": "8Iy8-roNvbce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# MERCOR AI TEXT DETECTION - Embeddings + XGBoost\n",
        "# ====================================================\n",
        "\n",
        "# ====================================================\n",
        "# 1 Cargar modelo de embeddings\n",
        "# ====================================================\n",
        "\n",
        "print(\"=== Fase 1 Star ===/n\")\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "print(\"Paciencia Cargando modelo de embeddings.../n\")\n",
        "model_emb = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "print(\"/n----- El Modelo se cargado correctamente -----\")\n",
        "\n",
        "print(\"=== Fase 1 Finish ===/n\")\n",
        "\n",
        "# ====================================================\n",
        "# 2 Importar librer√≠as POr si las dudas Nota para equipo : Borrar si no hay problemas\n",
        "# ====================================================\n",
        "print(\"=== Fase 2 Star===/n\")\n",
        "\n",
        "print(\"------ Por si las dudas volvere a cargar las librerias/n -------/n\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "print(\"=== Fase 2 Finish ===/n\")\n",
        "\n",
        "# ====================================================\n",
        "# 3 Cargar datos\n",
        "# ====================================================\n",
        "print(\"=== Fase 3 Star ===/n\")\n",
        "\n",
        "print(\"------ Paciencia Inicia Carga de Datos --------/n\")\n",
        "train_path = '/kaggle/input/mercor-ai-detection/train.csv'\n",
        "test_path = '/kaggle/input/mercor-ai-detection/test.csv'\n",
        "sample_path = '/kaggle/input/mercor-ai-detection/sample_submission.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "df_sample = pd.read_csv(sample_path)\n",
        "\n",
        "print(\"Los Datos cargados correctamente./n\")\n",
        "print(\"Tama√±o dataset entrenamiento:\", df_train.shape)\n",
        "print(\"Tama√±o dataset test:\", df_test.shape)\n",
        "\n",
        "print(\"=== Fase 3 Finish===/n\")\n",
        "\n",
        "# ====================================================\n",
        "# 4Ô∏è Preparar textos y etiquetas\n",
        "# ====================================================\n",
        "\n",
        "print(\"=== Fase 4 Star ===/n\")\n",
        "\n",
        "# Unir las columnas relevantes en un solo texto\n",
        "df_train['text'] = df_train['topic'].fillna('') + \" \" + df_train['answer'].fillna('')\n",
        "df_test['text'] = df_test['topic'].fillna('') + \" \" + df_test['answer'].fillna('')\n",
        "\n",
        "X = df_train['text']\n",
        "y = df_train['is_cheating']\n",
        "\n",
        "# Dividir datos en entrenamiento y validaci√≥n\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"=== Fase 4 Finish ===/n\")\n",
        "\n",
        "# ====================================================\n",
        "# 5 Crear Embeddings (SentenceTransformer)\n",
        "# ====================================================\n",
        "print(\"=== Fase 5 Star  ===/n\")\n",
        "\n",
        "print(\" Generando embeddings del conjunto de entrenamiento...\")\n",
        "X_train_emb = model_emb.encode(X_train.tolist(), show_progress_bar=True)\n",
        "\n",
        "print(\"üîπ Generando embeddings del conjunto de validaci√≥n...\")\n",
        "X_val_emb = model_emb.encode(X_val.tolist(), show_progress_bar=True)\n",
        "\n",
        "print(\"=== Fase 5 Finish===/n\")\n",
        "\n",
        "print(\"=== Fase 6 Star Modelo XGBooST ===/n\")\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 6 Entrenar modelo XGBoost\n",
        "# ====================================================\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "print(\"---- Paciencia Entrenando modelo XGBoost... ----\")\n",
        "xgb.fit(X_train_emb, y_train)\n",
        "\n",
        "print(\"=== Fase 6 Finish Backgrond===/n\")\n",
        "\n",
        "# ====================================================\n",
        "# 7 Evaluar modelo\n",
        "# ====================================================\n",
        "print(\"=== Fase 7 Star Evaluacion de Modelo ===/n\")\n",
        "print(\"\\n ----- Evaluando modelo... --------\")\n",
        "X_val_pred = xgb.predict(X_val_emb)\n",
        "X_val_prob = xgb.predict_proba(X_val_emb)[:, 1]\n",
        "\n",
        "roc = roc_auc_score(y_val, X_val_prob)\n",
        "f1 = f1_score(y_val, X_val_pred)\n",
        "acc = accuracy_score(y_val, X_val_pred)\n",
        "\n",
        "print(\"Resultados de Validaci√≥n/n\")\n",
        "print(classification_report(y_val, X_val_pred))\n",
        "print(f\"ROC AUC: {roc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"=== Fase 7 Finish Evaluacion de Modelo ===/n\")\n",
        "\n",
        "# ====================================================\n",
        "# 8 Generar predicciones sobre el test\n",
        "# ====================================================\n",
        "\n",
        "print(\"=== Fase 8 Star Embeddings ===/n\")\n",
        "\n",
        "print(\"\\n------ Generando embeddings del conjunto de prueba... -------\")\n",
        "X_test_emb = model_emb.encode(df_test['text'].tolist(), show_progress_bar=True)\n",
        "test_pred = xgb.predict_proba(X_test_emb)[:, 1]\n",
        "\n",
        "# Crear archivo de submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': df_test['id'],\n",
        "    'label': test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\n Archivo 'submission.csv' generado correctamente./n\")\n",
        "print(\"== Fase 8 Finish  Embeddings  ===/n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-22T04:06:20.813259Z",
          "iopub.execute_input": "2025-10-22T04:06:20.814444Z",
          "iopub.status.idle": "2025-10-22T04:07:19.752227Z",
          "shell.execute_reply.started": "2025-10-22T04:06:20.814407Z",
          "shell.execute_reply": "2025-10-22T04:07:19.751291Z"
        },
        "id": "3axMA5lCvbce",
        "outputId": "2473b6a7-debb-4f43-d856-33e73c8eebca",
        "colab": {
          "referenced_widgets": [
            "18202290bf65490ba27a70f14e0fc41d",
            "e8da2aa22c974c21a24b797dfaec2286",
            "bc4ae26f28be4bc29e155850270eba49"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "=== Fase 1 Star ===/n\nPaciencia Cargando modelo de embeddings.../n\n/n----- El Modelo se cargado correctamente -----\n=== Fase 1 Finish ===/n\n=== Fase 2 Star===/n\n------ Por si las dudas volvere a cargar las librerias/n -------/n\n=== Fase 2 Finish ===/n\n=== Fase 3 Star ===/n\n------ Paciencia Inicia Carga de Datos --------/n\nLos Datos cargados correctamente./n\nTama√±o dataset entrenamiento: (269, 4)\nTama√±o dataset test: (264, 3)\n=== Fase 3 Finish===/n\n=== Fase 4 Star ===/n\n=== Fase 4 Finish ===/n\n=== Fase 5 Star  ===/n\n Generando embeddings del conjunto de entrenamiento...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/7 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18202290bf65490ba27a70f14e0fc41d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "üîπ Generando embeddings del conjunto de validaci√≥n...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8da2aa22c974c21a24b797dfaec2286"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "=== Fase 5 Finish===/n\n=== Fase 6 Star Modelo XGBooST ===/n\n---- Paciencia Entrenando modelo XGBoost... ----\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:06:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"use_label_encoder\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "=== Fase 6 Finish Backgrond===/n\n=== Fase 7 Star Evaluacion de Modelo ===/n\n\n ----- Evaluando modelo... --------\nResultados de Validaci√≥n/n\n              precision    recall  f1-score   support\n\n           0       0.72      0.75      0.73        24\n           1       0.79      0.77      0.78        30\n\n    accuracy                           0.76        54\n   macro avg       0.76      0.76      0.76        54\nweighted avg       0.76      0.76      0.76        54\n\nROC AUC: 0.8722\nF1 Score: 0.7797\nAccuracy: 0.7593\n=== Fase 7 Finish Evaluacion de Modelo ===/n\n=== Fase 8 Star Embeddings ===/n\n\n------ Generando embeddings del conjunto de prueba... -------\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/9 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc4ae26f28be4bc29e155850270eba49"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n Archivo 'submission.csv' generado correctamente./n\n== Fase 8 Finish  Embeddings  ===/n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generacion del archivo . CSV para comparar"
      ],
      "metadata": {
        "id": "HOrjOAlsvbcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comando de visualizacion\n",
        "!ls -lh"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-22T04:13:41.972493Z",
          "iopub.execute_input": "2025-10-22T04:13:41.973675Z",
          "iopub.status.idle": "2025-10-22T04:13:42.181968Z",
          "shell.execute_reply.started": "2025-10-22T04:13:41.973624Z",
          "shell.execute_reply": "2025-10-22T04:13:42.180624Z"
        },
        "id": "eHAdB27Zvbcg",
        "outputId": "22a3f1f8-e1a7-4916-dc9c-0ac3639fe31a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "total 8.0K\n-rw-r--r-- 1 root root 7.2K Oct 22 04:07 submission.csv\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga del archivo\n",
        "from IPython.display import FileLink\n",
        "FileLink('submission.csv')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-22T04:14:01.157634Z",
          "iopub.execute_input": "2025-10-22T04:14:01.157998Z",
          "iopub.status.idle": "2025-10-22T04:14:01.166536Z",
          "shell.execute_reply.started": "2025-10-22T04:14:01.157964Z",
          "shell.execute_reply": "2025-10-22T04:14:01.165555Z"
        },
        "id": "ocO0aT16vbcg",
        "outputId": "5c8a5796-776f-4637-eef7-60a2f3993e8e"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "/kaggle/working/submission.csv",
            "text/html": "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}